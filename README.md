# TransformerRessources
A Repo containing various Ressources to Understand the Transformer model
![trans](./Transformer.png)
## Basics:
* The [Google Research Blog Article](https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html), describing the architecture + some good intuition tips
* [The Tensor2tensor lib ](https://github.com/tensorflow/tensor2tensor#language-modeling) to see the "official" implementation and experiment.
* [The explanation of Attention layer](http://nlp.seas.harvard.edu/2018/04/03/attention.html#Attention) wich are at the core of the model

## Advanced:
* Let's start with [Attention is all you need](https://arxiv.org/abs/1706.03762) The original Paper.
* A great Blog article By Harvard Nlp [Annotated Transformer](nlp.seas.harvard.edu/2018/04/03/attention.html). 
This paper give great Details (with code on the implementation)
* A great Article [Training Tips for the Transformer Model](https://arxiv.org/abs/1804.00247)
* a PyTorch implementation of the Transformer for NMT [Git here](https://github.com/huggingface/pytorch-openai-transformer-lm)
